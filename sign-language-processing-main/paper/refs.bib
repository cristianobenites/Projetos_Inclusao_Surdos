@article{PointNet,
  title={PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation},
  author={Qi, Charles R and Su, Hao and Mo, Kaichun and Guibas, Leonidas J},
  journal={arXiv preprint arXiv:1612.00593},
  year={2016}
}

@inproceedings{Neuspell,
    title = "{N}eu{S}pell: A Neural Spelling Correction Toolkit",
    author = "Jayanthi, Sai Muralidhar  and
      Pruthi, Danish  and
      Neubig, Graham",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = oct,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-demos.21",
    doi = "10.18653/v1/2020.emnlp-demos.21",
    pages = "158--164",
    abstract = "We introduce NeuSpell, an open-source toolkit for spelling correction in English. Our toolkit comprises ten different models, and benchmarks them on naturally occurring misspellings from multiple sources. We find that many systems do not adequately leverage the context around the misspelt token. To remedy this, (i) we train neural models using spelling errors in context, synthetically constructed by reverse engineering isolated misspellings; and (ii) use richer representations of the context. By training on our synthetic examples, correction rates improve by 9{\%} (absolute) compared to the case when models are trained on randomly sampled character perturbations. Using richer contextual representations boosts the correction rate by another 3{\%}. Our toolkit enables practitioners to use our proposed and existing spelling correction systems, both via a simple unified command line, as well as a web interface. Among many potential applications, we demonstrate the utility of our spell-checkers in combating adversarial misspellings. The toolkit can be accessed at neuspell.github.io.",
}

@inproceedings{SpellingItOut,
  author={Pugeault, Nicolas and Bowden, Richard},
  booktitle={2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops)}, 
  title={Spelling it out: Real-time ASL fingerspelling recognition}, 
  year={2011},
  volume={},
  number={},
  pages={1114-1119},
  keywords={Shape;Feature extraction;User interfaces;Handicapped aids;Vectors;Vegetation;Real time systems},
  doi={10.1109/ICCVW.2011.6130290}
  }

@inproceedings{FingerspellingInTheWild,
  author={Shi, Bowen and Rio, Aurora Martinez Del and Keane, Jonathan and Brentari, Diane and Shakhnarovich, Greg and Livescu, Karen},
  booktitle={2019 IEEE/CVF International Conference on Computer Vision (ICCV)}, 
  title={Fingerspelling Recognition in the Wild With Iterative Visual Attention}, 
  year={2019},
  volume={},
  number={},
  pages={5399-5408},
  keywords={Gesture recognition;Assistive technology;Visualization;Task analysis;Videos;Image recognition;Hidden Markov models},
  doi={10.1109/ICCV.2019.00550}
}

@inproceedings{SignLanguageDetection,
author = {Moryossef, Amit and Tsochantaridis, Ioannis and Aharoni, Roee and Ebling, Sarah and Narayanan, Srini},
title = {Real-Time Sign Language Detection Using Human Pose Estimation},
year = {2020},
isbn = {978-3-030-66095-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-66096-3_17},
doi = {10.1007/978-3-030-66096-3_17},
abstract = {We propose a lightweight real-time sign language detection model, as we identify the need for such a case in videoconferencing. We extract optical flow features based on human pose estimation and, using a linear classifier, show these features are meaningful with an accuracy of 80\%, evaluated on the Public DGS Corpus. Using a recurrent model directly on the input, we see improvements of up to 91\% accuracy, while still working under 4 ms. We describe a demo application to sign language detection in the browser in order to demonstrate its usage possibility in videoconferencing applications.},
booktitle = {Computer Vision – ECCV 2020 Workshops: Glasgow, UK, August 23–28, 2020, Proceedings, Part II},
pages = {237–248},
numpages = {12},
keywords = {Sign language processing, Sign language detection},
location = {Glasgow, United Kingdom}
}

@inproceedings{SignLanguageDetectionInTheWild,
  author={Borg, Mark and Camilleri, Kenneth P.},
  booktitle={ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Sign Language Detection “in the Wild” with Recurrent Neural Networks}, 
  year={2019},
  volume={},
  number={},
  pages={1637-1641},
  keywords={sign language detection;RNN;CNN},
  doi={10.1109/ICASSP.2019.8683257}
}

@inproceedings{SignLanguageSegmentation,
author = {Moryossef, Amit and Jiang, Zifan and Müller, Mathias and Ebling, Sarah and Goldberg, Yoav},
year = {2023},
month = {01},
pages = {12703-12724},
title = {Linguistically Motivated Sign Language Segmentation},
doi = {10.18653/v1/2023.findings-emnlp.846}
}

@inproceedings{TemporalSignLanguageSegmentation,
  author={Renz, Katrin and Stache, Nicolaj C. and Albanie, Samuel and Varol, Gül},
  booktitle={ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Sign Language Segmentation with Temporal Convolutional Networks}, 
  year={2021},
  volume={},
  number={},
  pages={2135-2139},
  keywords={Three-dimensional displays;Convolution;Assistive technology;Conferences;Training data;Gesture recognition;Iterative methods;Sign Language;Temporal Segmentation},
  doi={10.1109/ICASSP39728.2021.9413817}
}

@inproceedings{
PopSign,
title={PopSign {ASL} v1.0: An Isolated American Sign Language Dataset Collected via Smartphones},
author={Thad Starner and Sean Forbes and Matthew So and David Martin and Rohit Sridhar and Gururaj Deshpande and Sam Sepah and Sahir Shahryar and Khushi Bhardwaj and Tyler Kwok and others},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
year={2023},
url={https://openreview.net/forum?id=yEf8NSqTPu}
}

@inproceedings{Text2Gloss2Pose2Video,
    title = "An Open-Source Gloss-Based Baseline for Spoken to Signed Language Translation",
    author = {Moryossef, Amit  and
      M{\"u}ller, Mathias  and
      G{\"o}hring, Anne  and
      Jiang, Zifan  and
      Goldberg, Yoav  and
      Ebling, Sarah},
    editor = "Shterionov, Dimitar  and
      Sisto, Mirella De  and
      Muller, Mathias  and
      Landuyt, Davy Van  and
      Omardeen, Rehana  and
      Oboyle, Shaun  and
      Braffort, Annelies  and
      Roelofsen, Floris  and
      Blain, Fred  and
      Vanroy, Bram  and
      Avramidis, Eleftherios",
    booktitle = "Proceedings of the Second International Workshop on Automatic Translation for Signed and Spoken Languages",
    month = jun,
    year = "2023",
    address = "Tampere, Finland",
    publisher = "European Association for Machine Translation",
    url = "https://aclanthology.org/2023.at4ssl-1.3",
    pages = "22--33",
    abstract = "Sign language translation systems are complex and require many components. As a result, it is very hard to compare methods across publications. We present an open-source implementation of a text-to-gloss-to-pose-to-video pipeline approach, demonstrating conversion from German to Swiss German Sign Language, French to French Sign Language of Switzerland, and Italian to Italian Sign Language of Switzerland. We propose three different components for the text-to-gloss translation: a lemmatizer, a rule-based word reordering and dropping component, and a neural machine translation system. Gloss-to-pose conversion occurs using data from a lexicon for three different signed languages, with skeletal poses extracted from videos. To generate a sentence, the text-to-gloss system is first run, and the pose representations of the resulting signs are stitched together.",
}

@inproceedings{TransformerText2Gloss,
    title = "Syntax-aware Transformers for Neural Machine Translation: The Case of Text to Sign Gloss Translation",
    author = "Egea G{\'o}mez, Santiago  and
      McGill, Euan  and
      Saggion, Horacio",
    editor = "Rapp, Reinhard  and
      Sharoff, Serge  and
      Zweigenbaum, Pierre",
    booktitle = "Proceedings of the 14th Workshop on Building and Using Comparable Corpora (BUCC 2021)",
    month = sep,
    year = "2021",
    address = "Online (Virtual Mode)",
    publisher = "INCOMA Ltd.",
    url = "https://aclanthology.org/2021.bucc-1.4",
    pages = "18--27",
    abstract = "It is well-established that the preferred mode of communication of the deaf and hard of hearing (DHH) community are Sign Languages (SLs), but they are considered low resource languages where natural language processing technologies are of concern. In this paper we study the problem of text to SL gloss Machine Translation (MT) using Transformer-based architectures. Despite the significant advances of MT for spoken languages in the recent couple of decades, MT is in its infancy when it comes to SLs. We enrich a Transformer-based architecture aggregating syntactic information extracted from a dependency parser to word-embeddings. We test our model on a well-known dataset showing that the syntax-aware model obtains performance gains in terms of MT evaluation metrics.",
}

@inproceedings{Gloss2Pose,
author = {Stoll, Stephanie and Camgoz, Necati and Hadfield, Simon and Bowden, Richard},
year = {2018},
month = {08},
pages = {},
title = {Sign Language Production using Neural Machine Translation and Generative Adversarial Networks}
}

@inproceedings{MediaPipe,title	= {MediaPipe: A Framework for Perceiving and Processing Reality},author	= {Camillo Lugaresi and Jiuqiang Tang and Hadon Nash and Chris McClanahan and Esha Uboweja and Michael Hays and Fan Zhang and Chuo-Ling Chang and Ming Yong and Juhyun Lee and others},year	= {2019},URL	= {https://mixedreality.cs.cornell.edu/s/NewTitle_May1_MediaPipe_CVPR_CV4ARVR_Workshop_2019.pdf},booktitle	= {Third Workshop on Computer Vision for AR/VR at IEEE Computer Vision and Pattern Recognition (CVPR) 2019}}

@article{asllex,
    author = {Sehyr, Zed Sevcikova and Caselli, Naomi and Cohen-Goldberg, Ariel M and Emmorey, Karen},
    title = "{The ASL-LEX 2.0 Project: A Database of Lexical and Phonological Properties for 2,723 Signs in American Sign Language}",
    journal = {The Journal of Deaf Studies and Deaf Education},
    volume = {26},
    number = {2},
    pages = {263-277},
    year = {2021},
    month = {02},
    abstract = "{ASL-LEX is a publicly available, large-scale lexical database for American Sign Language (ASL). We report on the expanded database (ASL-LEX 2.0) that contains 2,723 ASL signs. For each sign, ASL-LEX now includes a more detailed phonological description, phonological density and complexity measures, frequency ratings (from deaf signers), iconicity ratings (from hearing non-signers and deaf signers), transparency (“guessability”) ratings (from non-signers), sign and videoclip durations, lexical class, and more. We document the steps used to create ASL-LEX 2.0 and describe the distributional characteristics for sign properties across the lexicon and examine the relationships among lexical and phonological properties of signs. Correlation analyses revealed that frequent signs were less iconic and phonologically simpler than infrequent signs and iconic signs tended to be phonologically simpler than less iconic signs. The complete ASL-LEX dataset and supplementary materials are available at https://osf.io/zpha4/ and an interactive visualization of the entire lexicon can be accessed on the ASL-LEX page: http://asl-lex.org/.}",
    issn = {1081-4159},
    doi = {10.1093/deafed/enaa038},
    url = {https://doi.org/10.1093/deafed/enaa038},
    eprint = {https://academic.oup.com/jdsde/article-pdf/26/2/263/36643382/enaa038.pdf},
}

@misc{gpt4o,
      title={GPT-4 Technical Report}, 
      author={OpenAI and Josh Achiam and Steven Adler and Sandhini Agarwal and Lama Ahmad and Ilge Akkaya and Florencia Leoni Aleman and Diogo Almeida and Janko Altenschmidt and Sam Altman and others},
      year={2024},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2303.08774}, 
}

@misc{whisper,
      title={Robust Speech Recognition via Large-Scale Weak Supervision}, 
      author={Alec Radford and Jong Wook Kim and Tao Xu and Greg Brockman and Christine McLeavey and Ilya Sutskever},
      year={2022},
      eprint={2212.04356},
      archivePrefix={arXiv},
      primaryClass={eess.AS},
      url={https://arxiv.org/abs/2212.04356}, 
}

@article{fingerspelling_stats,
 ISSN = {03021475, 15336263},
 URL = {http://www.jstor.org/stable/26204903},
 abstract = {This historical account of the development of the manual alphabet in ASL (and of representational systems in other sign languages) traces fingerspelling back to the monks of the seventh century, who devised a system for representing speech without needing to speak. Many years later, in the sixteenth and seventeenth centuries, their manual alphabet underwent significant adaptation as a result of the contact between the monks and the deaf children they tutored. This article describes the evolution of the manual alphabet from that time to the present day.},
 author = {CAROL A. PADDEN and DARLINE CLARK GUNSAULS},
 journal = {Sign Language Studies},
 number = {1},
 pages = {10--33},
 publisher = {Gallaudet University Press},
 title = {How the Alphabet Came to Be Used in a Sign Language},
 urldate = {2024-07-17},
 volume = {4},
 year = {2003}
}

@techreport{asl_stats,
author = {Mitchell, Ross and Young, Travas},
institution = {Gallaudet University},
year = {2022},
month = {08},
pages = {},
title = {How Many People Use Sign Language? A National Health Survey-Based Estimate}
}

@misc{Kaggle1,
    author = {Owen Fahey},
    year = {2022}, 
    title = {Synthetic ASL Alphabet}, 
    howpublished= {Kaggle, h\url{ttps://www.kaggle.com/datasets/lexset/synthetic-asl-alphabet}},
}

@misc{Kaggle2,
    author = {Dan Rasband},
    year = {2018}, 
    title = {ASL Alphabet Test}, 
    howpublished= {Kaggle, \url{https://www.kaggle.com/datasets/danrasband/asl-alphabet-test}},
}

@misc{Kaggle3,
    author = {Debashish Sau},
    year = {2021}, 
    title = {ASL (American Sign Language) Alphabet Dataset}, 
    howpublished= {Kaggle, \url{https://www.kaggle.com/datasets/debashishsau/aslamerican-sign-language-aplhabet-dataset}},
}

@misc{SLP, 
    title = "{S}ign {L}anguage {P}rocessing", 
    author = "Moryossef, Amit and Goldberg, Yoav",
    howpublished = "\url{https://sign-language-processing.github.io/}",
    year = "2021"
}

@article{chicago1,
author = {B. Shi, A. Martinez Del Rio, J. Keane, J. Michaux, D. Brentari, G. Shakhnarovich, and K. Livescu},
title = {American Sign Language fingerspelling recognition in the wild},
journal = {SLT},
year = {2018},
month = {December}
}

@article{chicago2,
author = {B. Shi, A. Martinez Del Rio, J. Keane, D. Brentari, G. Shakhnarovich, and K. Livescu},
title = {Fingerspelling recognition in the wild with iterative visual attention},
journal = {ICCV},
year = {2019},
month = {October}
}

@Article{numpy,
 title         = {Array programming with {NumPy}},
 author        = {Charles R. Harris and K. Jarrod Millman and St{\'{e}}fan J.
                 van der Walt and Ralf Gommers and Pauli Virtanen and David
                 Cournapeau and Eric Wieser and Julian Taylor and Sebastian
                 Berg and Nathaniel J. Smith and Robert Kern and Matti Picus
                 and Stephan Hoyer and Marten H. van Kerkwijk and Matthew
                 Brett and Allan Haldane and Jaime Fern{\'{a}}ndez del
                 R{\'{i}}o and Mark Wiebe and Pearu Peterson and Pierre
                 G{\'{e}}rard-Marchant and Kevin Sheppard and Tyler Reddy and
                 Warren Weckesser and Hameer Abbasi and Christoph Gohlke and
                 Travis E. Oliphant},
 year          = {2020},
 month         = sep,
 journal       = {Nature},
 volume        = {585},
 number        = {7825},
 pages         = {357--362},
 doi           = {10.1038/s41586-020-2649-2},
 publisher     = {Springer Science and Business Media {LLC}},
 url           = {https://doi.org/10.1038/s41586-020-2649-2}
}

@online{keras,
  title={Keras},
  author={Chollet, Francois and others},
  year={2015},
  publisher={GitHub},
  url={https://github.com/fchollet/keras},
}

@misc{tensorflow,
title={ {TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems},
url={https://www.tensorflow.org/},
note={Software available from tensorflow.org},
author={
    Mart\'{i}n~Abadi and
    Ashish~Agarwal and
    Paul~Barham and
    Eugene~Brevdo and
    Zhifeng~Chen and
    Craig~Citro and
    Greg~S.~Corrado and
    Andy~Davis and
    Jeffrey~Dean and
    Matthieu~Devin and others},
  year={2015},
}

@article{minilm,
  author       = {Wenhui Wang and
                  Furu Wei and
                  Li Dong and
                  Hangbo Bao and
                  Nan Yang and
                  Ming Zhou},
  title        = {MiniLM: Deep Self-Attention Distillation for Task-Agnostic Compression
                  of Pre-Trained Transformers},
  journal      = {CoRR},
  volume       = {abs/2002.10957},
  year         = {2020},
  url          = {https://arxiv.org/abs/2002.10957},
  eprinttype    = {arXiv},
  eprint       = {2002.10957},
  timestamp    = {Fri, 19 Apr 2024 15:54:57 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2002-10957.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}